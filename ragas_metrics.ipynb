{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07c30a69-6a66-4884-923d-6429f340c5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: ragas 0.1.8\n",
      "Uninstalling ragas-0.1.8:\n",
      "  Successfully uninstalled ragas-0.1.8\n",
      "Found existing installation: langchain-openai 0.2.9\n",
      "Uninstalling langchain-openai-0.2.9:\n",
      "  Successfully uninstalled langchain-openai-0.2.9\n",
      "Found existing installation: openai 1.55.1\n",
      "Uninstalling openai-1.55.1:\n",
      "  Successfully uninstalled openai-1.55.1\n",
      "zsh:1: 1.0.0 not found\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y ragas langchain-openai openai\n",
    "!pip install ragas==0.1.8 langchain-openai==0.0.5 openai>=1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2030d4f4-c221-41be-88df-881f187c9c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921ed5401ef94b0c86e0e12b6a4c5e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question  \\\n",
      "0  What criteria are used to evaluate the cost br...   \n",
      "1  What are the requirements for subcontractor re...   \n",
      "\n",
      "                                              answer  \\\n",
      "0  The evaluation criteria for the cost breakdown...   \n",
      "1  The requirements for subcontractor reporting u...   \n",
      "\n",
      "                                        ground_truth  answer_similarity  \n",
      "0  The Contractors' Cost Proposal submissions wil...           0.947655  \n",
      "1  Bidders awarded a contract with a commitment t...           0.952833  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from datasets import Dataset \n",
    "from ragas.metrics import answer_similarity\n",
    "from ragas import evaluate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from ragas.metrics._answer_similarity import AnswerSimilarity\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "data_samples = {\n",
    "    'question': [\n",
    "        \"What criteria are used to evaluate the cost breakdown in the Contractors' Cost Proposal submissions?\",\n",
    "        \"What are the requirements for subcontractor reporting under the California Disabled Veteran Business Enterprise (DVBE) program?\"\n",
    "    ],\n",
    "    'answer': [\n",
    "        \"The evaluation criteria for the cost breakdown in the Contractors' Cost Proposal submissions are outlined in the Request for Proposals (RFP) document issued by CalRecycle. The key points regarding the evaluation of the cost breakdown are as follows:1. **Detail Sufficiency**: The cost breakdown must be sufficiently detailed to determine if the proposed expenses are reasonable. This means that the Proposer must provide a clear and comprehensive breakdown of costs associated with each task.2. **Completion of Cost Proposal Sheet**: Proposers are required to complete Attachment C, the Cost Proposal Sheet, which must specify the total cost and include detailed project costs and subcontractor commitments identified by each task and dollar amount. 3. **Not to Exceed Percentages**: The Proposer must adhere to the 'not to exceed' percentages per task as noted in Attachment C. Each task has a specified maximum budget percentage that cannot be exceeded.4. **Itemization of Invoices**: The awarded Proposer’s invoices must be itemized as shown in the submitted Cost Proposal Sheet. This ensures transparency and accountability in billing.5. **Consideration of Contract Length and Costs**: The costs identified in Attachment C should take into account the contract length, potential rises in salaries, and overhead costs.6. **Fringe Benefits and Overhead**: If fringe benefits and/or overhead are not specifically itemized in Attachment C, and if the Proposer inserts a $0, an explanation must be provided. A blank space for either fringe benefits or overhead will lead to immediate disqualification.7. **Grounds for Disqualification**: Failure to include budgeted costs for all tasks included in the Scope of Work will also be grounds for disqualification.8. **Self-Contained Document**: The Cost Proposal Sheet is a self-contained document for calculating cost points and evaluating whether all required information has been submitted. Reference by incorporation to the Proposal is not acceptable, meaning all necessary information must be included directly in the Cost Proposal Sheet.These criteria ensure that the cost proposals are evaluated based on their clarity, completeness, and adherence to the specified guidelines, which are crucial for determining the reasonableness of the proposed expenses [DOCUMENT_ID:2f821df6-2c52-473f-acf9-4bf233cd31b1].\",\n",
    "        \"The requirements for subcontractor reporting under the California Disabled Veteran Business Enterprise (DVBE) program are as follows:\\n\\n1. **Certification of Payments**: Bidders awarded a contract with a commitment to use DVBE subcontractors must certify, upon completion of the contract, that all payments have been made to the DVBE subcontractors. This is done by submitting the Prime Contractor’s - DVBE Subcontracting Report (STD 817) [DOCUMENT_ID:3eb41f0e-85d5-4182-b486-54b65508a021].\\n\\n2. **Withholding of Payments**: For contracts awarded on or after January 1, 2021, the awarding department will withhold $10,000 from the final payment, or the full payment if the final payment is less than $10,000, from prime contractors until the complete and accurate STD 817 is received. If the certification is not submitted after being given the opportunity to cure, the department will permanently deduct $10,000 from the final payment or the full payment if it is less than $10,000 [DOCUMENT_ID:3eb41f0e-85d5-4182-b486-54b65508a021].\\n\\n3. **Proof of Payments**: The prime contractor must provide proof of payments made to DVBE subcontractors upon request from the department. This information will be kept in the procurement file for six years [DOCUMENT_ID:3eb41f0e-85d5-4182-b486-54b65508a021].\\n\\n4. **Reporting Requirements**: If the contractor made a commitment to achieve DVBE participation, they must certify in a report to the awarding department within 60 days of receiving final payment under the agreement. This report must include:\\n   - The total amount the prime contractor received under the contract.\\n   - The name and address of the DVBE(s) that participated in the performance of the contract.\\n   - The amount each DVBE received from the prime contractor.\\n   - Confirmation that all payments under the contract have been made to the DVBE(s).\\n   - The actual percentage of DVBE participation that was achieved [DOCUMENT_ID:3eb41f0e-85d5-4182-b486-54b65508a021].\\n\\nThese requirements ensure accountability and compliance with the DVBE program, promoting the participation of disabled veteran businesses in state contracts.\"\n",
    "    ],\n",
    "    'ground_truth': [\n",
    "        \"The Contractors' Cost Proposal submissions will be evaluated based on whether the cost breakdown is sufficiently detailed to determine if the proposed expenses are reasonable. Additionally, the Cost Proposal Sheet must be completed, specifying the total cost and including detailed project costs and subcontractor commitments identified by each task and dollar amount. The awarded Proposer\\u2019s invoices must be itemized as shown in the submitted Cost Proposal Sheet.\",\n",
    "        \"Bidders awarded a contract with a commitment to use DVBE subcontractors must certify, upon completion of the contract, that all payments have been made to the DVBE subcontractors by submitting the Prime Contractor\\u2019s - DVBE Subcontracting Report (STD 817). For contracts awarded on or after January 1, 2021, the department will withhold $10,000 from the final payment, or the full payment if the final payment is less than $10,000 from prime contractors, until the complete and accurate STD 817 is received. Failure to submit this certification after given the opportunity to cure will result in the department permanently deducting $10,000 from the final payment or the full payment if less than $10,000. The prime contractor shall provide proof of payments made to DVBE subcontractors at the request of the department, and the department shall keep all information provided by the prime contractor regarding the DVBE program requirements in the procurement file for six years.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "dataset = Dataset.from_dict(data_samples)\n",
    "\n",
    "score = evaluate(\n",
    "    dataset=dataset,\n",
    "    metrics=[answer_similarity]\n",
    ")\n",
    "\n",
    "print(score.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49921f88-7c6e-4d43-8266-45c3c65d36a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIEmbeddings\nopenai_api_key\n  Extra inputs are not permitted [type=extra_forbidden, input_value='no-key', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/extra_forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(pyarrow\u001b[38;5;241m.\u001b[39m__version__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ragas/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version \u001b[38;5;28;01mas\u001b[39;00m __version__\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ragas/evaluation.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, concatenate_datasets\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_analytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvaluationEvent, track\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Metric\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcritique\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AspectCritique\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     remap_column_names,\n\u001b[1;32m     14\u001b[0m     validate_column_dtypes,\n\u001b[1;32m     15\u001b[0m     validate_evaluation_modes,\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ragas/metrics/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_answer_correctness\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnswerCorrectness, answer_correctness\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_answer_relevance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnswerRelevancy, answer_relevancy\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_answer_similarity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnswerSimilarity, answer_similarity\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CallbackManager, trace_as_chain_group\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate, HumanMessagePromptTemplate\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_answer_similarity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnswerSimilarity\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvaluationMode, MetricWithLLM\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m json_loader\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ragas/metrics/_answer_similarity.py:93\u001b[0m\n\u001b[1;32m     88\u001b[0m             scores \u001b[38;5;241m=\u001b[39m scores \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 93\u001b[0m answer_similarity \u001b[38;5;241m=\u001b[39m AnswerSimilarity()\n",
      "File \u001b[0;32m<string>:7\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, batch_size, llm, name, evaluation_mode, embeddings, is_cross_encoder, threshold)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ragas/embeddings/base.py:163\u001b[0m, in \u001b[0;36membedding_factory\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membedding_factory\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RagasEmbeddings:\n\u001b[0;32m--> 163\u001b[0m     openai_embeddings \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings()\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m openai_embeddings\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ragas/embeddings/base.py:38\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.__init__\u001b[0;34m(self, api_key)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     openai_api_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28msuper\u001b[39m(BaseOpenAIEmbeddings, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(openai_api_key\u001b[38;5;241m=\u001b[39mopenai_api_key)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m openai_api_key\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pydantic/main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_validator__\u001b[38;5;241m.\u001b[39mvalidate_python(data, self_instance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    221\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAIEmbeddings\nopenai_api_key\n  Extra inputs are not permitted [type=extra_forbidden, input_value='no-key', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.10/v/extra_forbidden"
     ]
    }
   ],
   "source": [
    "data_samples = {\n",
    "    'question': ['When was the first super bowl?', 'Who won the most super bowls?'],\n",
    "    'answer': ['The first superbowl was held on Jan 15, 1967', 'The most super bowls have been won by The New England Patriots'],\n",
    "    'ground_truth': ['The first superbowl was held on January 15, 1967', 'The New England Patriots have won the Super Bowl a record six times']\n",
    "}\n",
    "dataset = Dataset.from_dict(data_samples)\n",
    "score = evaluate(dataset,metrics=[answer_similarity])\n",
    "score.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3dc9a3-1b8e-4f83-92ad-acb6c2953da8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
